---
title: 'Lightfield Photography'
permalink: /posts/lightfield/
excerpt_separator: <!--more-->
tags:
  - lightfield
  - photography
header:
   teaser: lightfield.png
---

The light field is the full description of light as it travels in all directions through space around us. 
It can be thought of as being made up of infinitely many light ray vectors, each with a direction of propagation and a magnitude that is proportional to their intensity. 
As humans, we view the world by interpreting the intensity and frequency of the subset of light rays that intersect our eyes. 
However, our eyes, just like standard cameras, are incapable of recording the direction of these light rays.
Recording the direction of these light rays allows for the light field to be fully defined at a given location.
In this post I provide an introduction to the lightfield and lightfield photography.

<!--more-->


# Light

Visible light propagates through space as part of the electromagnetic spectrum.
This part of the electromagnetic spectrum incorporates frequencies of between 430 and 700 Terahertz (THz), and contains within it all the colours that we see. These colours are visible to us due to the different frequencies at which light is reflected and absorbed by different objects. 
Light can also be deflected when it passes through an object, in a phenomenon known as refraction. 
It is refraction that allows light to be focused by a lens onto an image sensor.


<!-- 
# Lightfield Photography

Light field photography allows the direction of light rays to be captured. 
This means that a higher dimensional representation of light is captured by a light field camera compared to a standard camera. Light field cameras therefore provide a new, more detailed way of sensing light in an environment. 
This dense sensor information is already being applied to existing applications within the research fields of robotics and computer vision. 
Such applications include odometry, depth mapping, 3D image reconstruction, and image filtering. 
By capturing more information about a scene, these applications are able to gain more information from a single
image. 
For example, 3D image reconstruction requires multiple images of a scene to be taken taken from different, known camera poses. This method is referred to as ‘stereo vision’. 
The directional dimensions that are added by taking multiple standard images are captured in a single light field image.
 -->


